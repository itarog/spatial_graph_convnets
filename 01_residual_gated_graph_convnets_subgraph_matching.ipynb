{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Gated Graph ConvNets\n",
    "### Xavier Bresson, Jan. 15 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda not available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pdb \n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "    #torch.cuda.manual_seed(1)\n",
    "else:\n",
    "    print('cuda not available')\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor\n",
    "    #torch.manual_seed(1)\n",
    "    \n",
    "# import files in folder util\n",
    "import sys\n",
    "sys.path.insert(0, 'util/')\n",
    "import block \n",
    "import graph_generator as g\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "TASK_INDEX=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flag_task': 'clustering', 'nb_communities': 10, 'nb_clusters_target': 10, 'Voc': 11, 'size_min': 5, 'size_max': 25, 'p': 0.5, 'q': 0.1, 'all_trainx': [[0, <graph_generator.graph_semi_super_clu object at 0x000001F40B21E3C8>], [1, <graph_generator.graph_semi_super_clu object at 0x000001F40B218208>], [2, <graph_generator.graph_semi_super_clu object at 0x000001F40B21AE08>], [3, <graph_generator.graph_semi_super_clu object at 0x000001F40B21A048>], [4, <graph_generator.graph_semi_super_clu object at 0x000001F40B0A5808>], [5, <graph_generator.graph_semi_super_clu object at 0x000001F40B0A5DC8>], [6, <graph_generator.graph_semi_super_clu object at 0x000001F40B0A5708>], [7, <graph_generator.graph_semi_super_clu object at 0x000001F40B204708>], [8, <graph_generator.graph_semi_super_clu object at 0x000001F40B204B48>], [9, <graph_generator.graph_semi_super_clu object at 0x000001F40B204E08>], [10, <graph_generator.graph_semi_super_clu object at 0x000001F40A634108>], [11, <graph_generator.graph_semi_super_clu object at 0x000001F40B0A06C8>], [12, <graph_generator.graph_semi_super_clu object at 0x000001F4637A9348>], [13, <graph_generator.graph_semi_super_clu object at 0x000001F40B224208>], [14, <graph_generator.graph_semi_super_clu object at 0x000001F40B224BC8>], [15, <graph_generator.graph_semi_super_clu object at 0x000001F40B273908>], [16, <graph_generator.graph_semi_super_clu object at 0x000001F40B274888>], [17, <graph_generator.graph_semi_super_clu object at 0x000001F40B272188>], [18, <graph_generator.graph_semi_super_clu object at 0x000001F40B2726C8>], [19, <graph_generator.graph_semi_super_clu object at 0x000001F40B280548>], [20, <graph_generator.graph_semi_super_clu object at 0x000001F40B28B588>], [21, <graph_generator.graph_semi_super_clu object at 0x000001F40B28E308>], [22, <graph_generator.graph_semi_super_clu object at 0x000001F40B279808>], [23, <graph_generator.graph_semi_super_clu object at 0x000001F40B279A88>], [24, <graph_generator.graph_semi_super_clu object at 0x000001F40B275EC8>], [25, <graph_generator.graph_semi_super_clu object at 0x000001F40B29CF08>], [26, <graph_generator.graph_semi_super_clu object at 0x000001F40B28FE08>], [27, <graph_generator.graph_semi_super_clu object at 0x000001F40B2882C8>], [28, <graph_generator.graph_semi_super_clu object at 0x000001F40B276308>], [29, <graph_generator.graph_semi_super_clu object at 0x000001F40B29E788>], [30, <graph_generator.graph_semi_super_clu object at 0x000001F40B2A27C8>], [31, <graph_generator.graph_semi_super_clu object at 0x000001F40B2A5C48>], [32, <graph_generator.graph_semi_super_clu object at 0x000001F40B2A8C88>], [33, <graph_generator.graph_semi_super_clu object at 0x000001F40B2AF148>], [34, <graph_generator.graph_semi_super_clu object at 0x000001F40B233188>], [35, <graph_generator.graph_semi_super_clu object at 0x000001F40B235608>], [36, <graph_generator.graph_semi_super_clu object at 0x000001F40B239648>], [37, <graph_generator.graph_semi_super_clu object at 0x000001F40B23DAC8>], [38, <graph_generator.graph_semi_super_clu object at 0x000001F40B242B08>], [39, <graph_generator.graph_semi_super_clu object at 0x000001F40B244308>], [40, <graph_generator.graph_semi_super_clu object at 0x000001F40B244588>], [41, <graph_generator.graph_semi_super_clu object at 0x000001F40B244808>], [42, <graph_generator.graph_semi_super_clu object at 0x000001F40B244A88>], [43, <graph_generator.graph_semi_super_clu object at 0x000001F40B244D08>], [44, <graph_generator.graph_semi_super_clu object at 0x000001F40B244F88>], [45, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E2248>], [46, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E24C8>], [47, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E2748>], [48, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E29C8>], [49, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E2C48>], [50, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E2EC8>], [51, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5188>], [52, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5408>], [53, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5688>], [54, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5908>], [55, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5B88>], [56, <graph_generator.graph_semi_super_clu object at 0x000001F40D2E5E08>], [57, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EF0C8>], [58, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EF348>], [59, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EF5C8>], [60, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EF848>], [61, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EFAC8>], [62, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EFD48>], [63, <graph_generator.graph_semi_super_clu object at 0x000001F40D2EFFC8>], [64, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1288>], [65, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1508>], [66, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1788>], [67, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1A08>], [68, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1C88>], [69, <graph_generator.graph_semi_super_clu object at 0x000001F40D2F1F08>], [70, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FB1C8>], [71, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FB448>], [72, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FB6C8>], [73, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FB948>], [74, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FBBC8>], [75, <graph_generator.graph_semi_super_clu object at 0x000001F40D2FBE48>], [76, <graph_generator.graph_semi_super_clu object at 0x000001F40D301108>], [77, <graph_generator.graph_semi_super_clu object at 0x000001F40D301388>], [78, <graph_generator.graph_semi_super_clu object at 0x000001F40D301608>], [79, <graph_generator.graph_semi_super_clu object at 0x000001F40D301888>], [80, <graph_generator.graph_semi_super_clu object at 0x000001F40D301B08>], [81, <graph_generator.graph_semi_super_clu object at 0x000001F40D301D88>], [82, <graph_generator.graph_semi_super_clu object at 0x000001F40D307048>], [83, <graph_generator.graph_semi_super_clu object at 0x000001F40D3072C8>], [84, <graph_generator.graph_semi_super_clu object at 0x000001F40D307548>], [85, <graph_generator.graph_semi_super_clu object at 0x000001F40D3077C8>], [86, <graph_generator.graph_semi_super_clu object at 0x000001F40D307A48>], [87, <graph_generator.graph_semi_super_clu object at 0x000001F40D307CC8>], [88, <graph_generator.graph_semi_super_clu object at 0x000001F40D307F48>], [89, <graph_generator.graph_semi_super_clu object at 0x000001F40D30E208>], [90, <graph_generator.graph_semi_super_clu object at 0x000001F40D30E488>], [91, <graph_generator.graph_semi_super_clu object at 0x000001F40D30E708>], [92, <graph_generator.graph_semi_super_clu object at 0x000001F40D30E988>], [93, <graph_generator.graph_semi_super_clu object at 0x000001F40D30EC08>], [94, <graph_generator.graph_semi_super_clu object at 0x000001F40D30EE88>], [95, <graph_generator.graph_semi_super_clu object at 0x000001F40F2E3148>], [96, <graph_generator.graph_semi_super_clu object at 0x000001F40F2E33C8>], [97, <graph_generator.graph_semi_super_clu object at 0x000001F40F2E3648>], [98, <graph_generator.graph_semi_super_clu object at 0x000001F40F2E38C8>], [99, <graph_generator.graph_semi_super_clu object at 0x000001F40F2E3B48>]]}\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# select task and task parameters\n",
    "#################\n",
    "\n",
    "# subgraph matching\n",
    "if TASK_INDEX==1:\n",
    "    task_parameters = {}\n",
    "    task_parameters['flag_task'] = 'matching'\n",
    "    task_parameters['nb_communities'] = 10\n",
    "    task_parameters['nb_clusters_target'] = 2\n",
    "    task_parameters['Voc'] = 3\n",
    "    task_parameters['size_min'] = 15\n",
    "    task_parameters['size_max'] = 25\n",
    "    task_parameters['size_subgraph'] = 20\n",
    "    task_parameters['p'] = 0.5\n",
    "    task_parameters['q'] = 0.1\n",
    "    task_parameters['W0'] = block.random_graph(task_parameters['size_subgraph'],task_parameters['p']) # the sub graph  20x20\n",
    "    task_parameters['u0'] = np.random.randint(task_parameters['Voc'],size=task_parameters['size_subgraph'])\n",
    "    file_name = 'data/set_100_subgraphs_p05_size20_Voc3_2017-10-31_10-23-00_.txt'\n",
    "    with open(file_name, 'rb') as fp:\n",
    "        all_trainx = pickle.load(fp) # list of tuples [(sample_index, 20x20 adj matrix)]\n",
    "    task_parameters['all_trainx'] = all_trainx[:100]\n",
    "    \n",
    "# semi-supervised clustering\n",
    "if TASK_INDEX==2:\n",
    "    task_parameters = {}\n",
    "    task_parameters['flag_task'] = 'clustering'\n",
    "    task_parameters['nb_communities'] = 10\n",
    "    task_parameters['nb_clusters_target'] = task_parameters['nb_communities']\n",
    "    task_parameters['Voc'] = task_parameters['nb_communities'] + 1\n",
    "    task_parameters['size_min'] = 5\n",
    "    task_parameters['size_max'] = 25\n",
    "    task_parameters['p'] = 0.5\n",
    "    task_parameters['q'] = 0.1  \n",
    "    file_name = 'data/set_100_clustering_maps_p05_q01_size5_25_2017-10-31_10-25-00_.txt'\n",
    "    with open(file_name, 'rb') as fp:\n",
    "        all_trainx = pickle.load(fp)\n",
    "    task_parameters['all_trainx'] = all_trainx[:100]\n",
    "print(task_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B0A5EC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F4637A1C08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A654348>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A654788>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A654108>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A654A88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A654648>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B27F908>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B27FCC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B27FBC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B27F688>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B27F648>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B09AEC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B09A108>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B0A0188>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40A619B88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B09ADC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B0ADF48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B20C6C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B20CE08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B214588>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B214CC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21D448>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21DB88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B1F6308>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B1F6A48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B20E1C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B20E908>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B210088>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2107C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B210F08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B211208>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B211788>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B213E08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B213308>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B206408>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B206B48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21F8C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21FE08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2186C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B218E08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21A088>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21AD88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B21A7C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B22F648>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B22FD88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B224508>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B224C48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B273288>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B273AC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B274D48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B274248>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B272208>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B272D48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B272888>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B280E88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B280048>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28B608>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28BD48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28E4C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28EC08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B279388>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B279AC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B275608>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B275988>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B29C108>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B29C848>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B29CF88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28F708>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B28FE48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2985C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B298D08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B288488>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B288BC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B276348>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B276A88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B29E208>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B29E948>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A20C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A2808>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A2F48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A56C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A5E08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A8588>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2A8CC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2AC448>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2ACB88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2AF308>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2AFA48>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2331C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B233908>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B235088>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B2357C8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B235F08>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B239688>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B239DC8>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B23D548>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B23DC88>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B242408>\n",
      "<graph_generator.graph_semi_super_clu object at 0x000001F40B242B48>\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(all_trainx[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_parameters['u0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# Class cell definition\n",
    "##############################\n",
    "class OurConvNetcell(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(OurConvNetcell, self).__init__()\n",
    "\n",
    "        # conv1\n",
    "        self.Ui1 = nn.Linear(dim_in, dim_out, bias=False) \n",
    "        self.Uj1 = nn.Linear(dim_in, dim_out, bias=False)\n",
    "        self.Vi1 = nn.Linear(dim_in, dim_out, bias=False) \n",
    "        self.Vj1 = nn.Linear(dim_in, dim_out, bias=False)  \n",
    "        self.bu1 = torch.nn.Parameter( torch.FloatTensor(dim_out), requires_grad=True )\n",
    "        self.bv1 = torch.nn.Parameter( torch.FloatTensor(dim_out), requires_grad=True )\n",
    "        \n",
    "        # conv2\n",
    "        self.Ui2 = nn.Linear(dim_out, dim_out, bias=False) \n",
    "        self.Uj2 = nn.Linear(dim_out, dim_out, bias=False)\n",
    "        self.Vi2 = nn.Linear(dim_out, dim_out, bias=False) \n",
    "        self.Vj2 = nn.Linear(dim_out, dim_out, bias=False)  \n",
    "        self.bu2 = torch.nn.Parameter( torch.FloatTensor(dim_out), requires_grad=True )\n",
    "        self.bv2 = torch.nn.Parameter( torch.FloatTensor(dim_out), requires_grad=True )\n",
    "        \n",
    "        # bn1, bn2\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim_out)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim_out)\n",
    "        \n",
    "        # resnet\n",
    "        self.R = nn.Linear(dim_in, dim_out, bias=False) \n",
    "            \n",
    "        # init\n",
    "        self.init_weights_OurConvNetcell(dim_in, dim_out, 1)\n",
    "        \n",
    "         \n",
    "    def init_weights_OurConvNetcell(self, dim_in, dim_out, gain):\n",
    "        \n",
    "        # conv1\n",
    "        scale = gain* np.sqrt( 2.0/ dim_in )\n",
    "        self.Ui1.weight.data.uniform_(-scale, scale) \n",
    "        self.Uj1.weight.data.uniform_(-scale, scale) \n",
    "        self.Vi1.weight.data.uniform_(-scale, scale) \n",
    "        self.Vj1.weight.data.uniform_(-scale, scale) \n",
    "        scale = gain* np.sqrt( 2.0/ dim_out )\n",
    "        self.bu1.data.fill_(0)\n",
    "        self.bv1.data.fill_(0)\n",
    "        \n",
    "        # conv2\n",
    "        scale = gain* np.sqrt( 2.0/ dim_out )\n",
    "        self.Ui2.weight.data.uniform_(-scale, scale) \n",
    "        self.Uj2.weight.data.uniform_(-scale, scale) \n",
    "        self.Vi2.weight.data.uniform_(-scale, scale) \n",
    "        self.Vj2.weight.data.uniform_(-scale, scale) \n",
    "        scale = gain* np.sqrt( 2.0/ dim_out )\n",
    "        self.bu2.data.fill_(0)\n",
    "        self.bv2.data.fill_(0)\n",
    "        \n",
    "        # RN\n",
    "        scale = gain* np.sqrt( 2.0/ dim_in )\n",
    "        self.R.weight.data.uniform_(-scale, scale)  \n",
    "            \n",
    "            \n",
    "    def forward(self, x, E_start, E_end):\n",
    "        \n",
    "        # E_start, E_end : E x V\n",
    "\n",
    "        xin = x\n",
    "        # conv1\n",
    "        Vix = self.Vi1(x)  #  V x H_out\n",
    "        Vjx = self.Vj1(x)  #  V x H_out\n",
    "        x1 = torch.mm(E_end,Vix) + torch.mm(E_start,Vjx) + self.bv1  # E x H_out\n",
    "        x1 = torch.sigmoid(x1) # F.sigmoid(x1)\n",
    "        Ujx = self.Uj1(x)  #  V x H_out\n",
    "        x2 = torch.mm(E_start, Ujx)  #  V x H_out\n",
    "        Uix = self.Ui1(x)  #  V x H_out\n",
    "        x = Uix + torch.mm(E_end.t(), x1*x2) + self.bu1 #  V x H_out\n",
    "        # bn1\n",
    "        x = self.bn1(x)\n",
    "        # relu1\n",
    "        x = F.relu(x)\n",
    "        # conv2\n",
    "        Vix = self.Vi2(x)  #  V x H_out\n",
    "        Vjx = self.Vj2(x)  #  V x H_out\n",
    "        x1 = torch.mm(E_end,Vix) + torch.mm(E_start,Vjx) + self.bv2  # E x H_out\n",
    "        x1 = torch.sigmoid(x1) # F.sigmoid(x1)\n",
    "        Ujx = self.Uj2(x)  #  V x H_out\n",
    "        x2 = torch.mm(E_start, Ujx)  #  V x H_out\n",
    "        Uix = self.Ui2(x)  #  V x H_out\n",
    "        x = Uix + torch.mm(E_end.t(), x1*x2) + self.bu2 #  V x H_out\n",
    "        # bn2\n",
    "        x = self.bn2(x)\n",
    "        # addition\n",
    "        x = x + self.R(xin)\n",
    "        # relu2\n",
    "        x = F.relu(x)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "                \n",
    "##############################\n",
    "# Class NN definition\n",
    "##############################  \n",
    "class Graph_OurConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, net_parameters):\n",
    "        \n",
    "        super(Graph_OurConvNet, self).__init__()\n",
    "        \n",
    "        # parameters\n",
    "        flag_task = task_parameters['flag_task']\n",
    "        Voc = net_parameters['Voc']\n",
    "        D = net_parameters['D']\n",
    "        nb_clusters_target = net_parameters['nb_clusters_target']\n",
    "        H = net_parameters['H']\n",
    "        L = net_parameters['L']\n",
    "        \n",
    "        # vector of hidden dimensions\n",
    "        net_layers = []\n",
    "        for layer in range(L):\n",
    "            net_layers.append(H)\n",
    "\n",
    "        # embedding\n",
    "        self.encoder = nn.Embedding(Voc, D)      \n",
    "        \n",
    "        # CL cells\n",
    "        # NOTE: Each graph convnet cell uses *TWO* convolutional operations\n",
    "        net_layers_extended = [D] + net_layers # include embedding dim\n",
    "        L = len(net_layers)\n",
    "        list_of_gnn_cells = [] # list of NN cells\n",
    "        for layer in range(L//2):\n",
    "            Hin, Hout = net_layers_extended[2*layer], net_layers_extended[2*layer+2]\n",
    "            list_of_gnn_cells.append(OurConvNetcell(Hin,Hout))\n",
    "            \n",
    "        # register the cells for pytorch\n",
    "        self.gnn_cells = nn.ModuleList(list_of_gnn_cells)\n",
    "              \n",
    "        # fc\n",
    "        Hfinal = net_layers_extended[-1]\n",
    "        self.fc = nn.Linear(Hfinal,nb_clusters_target) \n",
    "        \n",
    "        # init\n",
    "        self.init_weights_Graph_OurConvNet(Voc,D,Hfinal,nb_clusters_target,1)\n",
    "        \n",
    "        # print\n",
    "        print('\\nnb of hidden layers=',L)\n",
    "        print('dim of layers (w/ embed dim)=',net_layers_extended)      \n",
    "        print('\\n')\n",
    "        \n",
    "        # class variables\n",
    "        self.L = L\n",
    "        self.net_layers_extended = net_layers_extended      \n",
    "        self.flag_task = flag_task\n",
    "        \n",
    "        \n",
    "    def init_weights_Graph_OurConvNet(self, Fin_enc, Fout_enc, Fin_fc, Fout_fc, gain):\n",
    "\n",
    "        scale = gain* np.sqrt( 2.0/ Fin_enc )\n",
    "        self.encoder.weight.data.uniform_(-scale, scale)  \n",
    "        scale = gain* np.sqrt( 2.0/ Fin_fc )\n",
    "        self.fc.weight.data.uniform_(-scale, scale)  \n",
    "        self.fc.bias.data.fill_(0)  \n",
    "    \n",
    "            \n",
    "    def forward(self, G):\n",
    "        \n",
    "        # signal\n",
    "        x = G.signal  # V-dim\n",
    "        x = Variable( torch.LongTensor(x).type(dtypeLong) , requires_grad=False)\n",
    "           \n",
    "        # encoder\n",
    "        x_emb = self.encoder(x) # V x D\n",
    "        \n",
    "        # graph operators\n",
    "        # Edge = start vertex to end vertex\n",
    "        # E_start = E x V mapping matrix from edge index to corresponding start vertex\n",
    "        # E_end = E x V mapping matrix from edge index to corresponding end vertex\n",
    "        E_start = G.edge_to_starting_vertex\n",
    "        E_end   = G.edge_to_ending_vertex \n",
    "        E_start = torch.from_numpy(E_start.toarray()).type(dtypeFloat)\n",
    "        E_end = torch.from_numpy(E_end.toarray()).type(dtypeFloat) \n",
    "        E_start = Variable( E_start , requires_grad=False) \n",
    "        E_end = Variable( E_end , requires_grad=False) \n",
    "        \n",
    "        # convnet cells  \n",
    "        x = x_emb\n",
    "        for layer in range(self.L//2):\n",
    "            gnn_layer = self.gnn_cells[layer]            \n",
    "            x = gnn_layer(x,E_start,E_end) # V x Hfinal\n",
    "            \n",
    "        # FC\n",
    "        x = self.fc(x)   \n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def loss(self, y, y_target, weight):\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss(weight=weight.type(dtypeFloat))(y,y_target)\n",
    "        \n",
    "        return loss\n",
    "       \n",
    "        \n",
    "    def update(self, lr):\n",
    "                \n",
    "        update = torch.optim.Adam( self.parameters(), lr=lr )\n",
    "        \n",
    "        return update\n",
    "    \n",
    "    \n",
    "    def update_learning_rate(self, optimizer, lr):\n",
    "   \n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def nb_param(self):\n",
    "\n",
    "        return self.nb_param    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################\n",
    "# network and optimization parameters\n",
    "#################\n",
    "\n",
    "# network parameters\n",
    "net_parameters = {}\n",
    "net_parameters['Voc'] = task_parameters['Voc']\n",
    "net_parameters['D'] = 50\n",
    "net_parameters['nb_clusters_target'] = task_parameters['nb_clusters_target']\n",
    "net_parameters['H'] = 50\n",
    "net_parameters['L'] = 10\n",
    "# print(net_parameters)\n",
    "\n",
    "\n",
    "# optimization parameters\n",
    "opt_parameters = {}\n",
    "opt_parameters['learning_rate'] = 0.00075   # ADAM\n",
    "opt_parameters['max_iters'] = 5000   \n",
    "opt_parameters['batch_iters'] = 100\n",
    "if 2==1: # fast debugging\n",
    "    opt_parameters['max_iters'] = 101 \n",
    "    opt_parameters['batch_iters'] = 10\n",
    "opt_parameters['decay_rate'] = 1.25   \n",
    "#print(opt_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# Graph convnet function\n",
    "#########################\n",
    "def our_graph_convnets(task_parameters,net_parameters,opt_parameters):\n",
    "\n",
    "\n",
    "    # Delete existing network if exists\n",
    "    try:\n",
    "        del net\n",
    "        print('Delete existing network\\n')\n",
    "    except NameError:\n",
    "        print('No existing network to delete\\n')\n",
    "\n",
    "\n",
    "    # instantiate\n",
    "    net = Graph_OurConvNet(net_parameters)\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    print(net)\n",
    "    \n",
    "    \n",
    "    # number of network parameters\n",
    "    nb_param = 0\n",
    "    for param in net.parameters():\n",
    "        nb_param += np.prod(list(param.data.size()))\n",
    "    print('nb_param=',nb_param,' L=',net_parameters['L'])\n",
    "    \n",
    "\n",
    "    # task parameters\n",
    "    flag_task = task_parameters['flag_task']\n",
    "    # network parameters\n",
    "    Voc = net_parameters['Voc']\n",
    "    D = net_parameters['D']\n",
    "    nb_clusters_target = net_parameters['nb_clusters_target']\n",
    "    H = net_parameters['H']\n",
    "    L = net_parameters['L']\n",
    "    # optimization parameters\n",
    "    learning_rate = opt_parameters['learning_rate']\n",
    "    max_iters = opt_parameters['max_iters']\n",
    "    batch_iters = opt_parameters['batch_iters']\n",
    "    decay_rate = opt_parameters['decay_rate']\n",
    "    \n",
    "    \n",
    "    # Optimizer\n",
    "    global_lr = learning_rate\n",
    "    global_step = 0\n",
    "    lr = learning_rate\n",
    "    optimizer = net.update(lr) \n",
    "\n",
    "    \n",
    "    #############\n",
    "    # loop over epochs\n",
    "    #############\n",
    "    t_start = time.time()\n",
    "    t_start_total = time.time()\n",
    "    average_loss_old = 1e10\n",
    "    running_loss = 0.0\n",
    "    running_total = 0\n",
    "    running_conf_mat = 0\n",
    "    running_accuracy = 0\n",
    "    tab_results = []\n",
    "    for iteration in range(1*max_iters):  # loop over the dataset multiple times\n",
    "\n",
    "        # generate one train graph\n",
    "        if flag_task=='matching': # subgraph matching\n",
    "            train_x = g.variable_size_graph(task_parameters)\n",
    "            for point in train_x: \n",
    "                print(point)\n",
    "                exit()\n",
    "        elif flag_task=='clustering': # semi supervised clustering\n",
    "            train_x = g.graph_semi_super_clu(task_parameters)\n",
    "        train_y = train_x.target\n",
    "        train_y = Variable( torch.LongTensor(train_y).type(dtypeLong) , requires_grad=False) \n",
    "\n",
    "        # forward, loss\n",
    "        y = net.forward(train_x)\n",
    "        # compute loss weigth\n",
    "        labels = train_y.data.cpu().numpy()\n",
    "        V = labels.shape[0]\n",
    "        nb_classes = len(np.unique(labels)) \n",
    "        cluster_sizes = np.zeros(nb_classes)\n",
    "        for r in range(nb_classes):\n",
    "            cluster = np.where(labels==r)[0]\n",
    "            cluster_sizes[r] = len(cluster)    \n",
    "        weight = torch.zeros(nb_classes)\n",
    "        for r in range(nb_classes):\n",
    "            sumj = 0\n",
    "            for j in range(nb_classes):\n",
    "                if j!=r:\n",
    "                    sumj += cluster_sizes[j]\n",
    "            weight[r] = sumj/ V \n",
    "        loss = net.loss(y,train_y,weight)\n",
    "        loss_train = loss.data #[0]\n",
    "        running_loss += loss_train\n",
    "        running_total += 1\n",
    "\n",
    "        # confusion matrix\n",
    "        S = train_y.data.cpu().numpy()\n",
    "        C = np.argmax( torch.nn.Softmax(dim=0)(y).data.cpu().numpy() , axis=1)\n",
    "        CM = confusion_matrix(S,C).astype(np.float32)\n",
    "        nb_classes = CM.shape[0]\n",
    "        train_y = train_y.data.cpu().numpy()\n",
    "        for r in range(nb_classes):\n",
    "            cluster = np.where(train_y==r)[0]\n",
    "            CM[r,:] /= cluster.shape[0]\n",
    "        running_conf_mat += CM\n",
    "        running_accuracy += np.sum(np.diag(CM))/ nb_classes\n",
    "\n",
    "        # backward, update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # learning rate, print results\n",
    "        if not iteration%batch_iters:\n",
    "\n",
    "            # time\n",
    "            t_stop = time.time() - t_start\n",
    "            t_start = time.time()\n",
    "\n",
    "            # confusion matrix\n",
    "            average_conf_mat = running_conf_mat/ running_total\n",
    "            running_conf_mat = 0\n",
    "\n",
    "            # accuracy\n",
    "            average_accuracy = running_accuracy/ running_total\n",
    "            running_accuracy = 0\n",
    "\n",
    "            # update learning rate \n",
    "            average_loss = running_loss/ running_total\n",
    "            if average_loss > 0.99* average_loss_old:\n",
    "                lr /= decay_rate\n",
    "            average_loss_old = average_loss\n",
    "            optimizer = net.update_learning_rate(optimizer, lr)\n",
    "            running_loss = 0.0\n",
    "            running_total = 0\n",
    "\n",
    "            # save intermediate results\n",
    "            tab_results.append([iteration,average_loss,100* average_accuracy,time.time()-t_start_total])\n",
    "\n",
    "            # print results\n",
    "            if 1==1:\n",
    "                print('\\niteration= %d, loss(%diter)= %.3f, lr= %.8f, time(%diter)= %.2f' % \n",
    "                      (iteration, batch_iters, average_loss, lr, batch_iters, t_stop))\n",
    "                #print('Confusion matrix= \\n', 100* average_conf_mat)\n",
    "                print('accuracy= %.3f' % (100* average_accuracy))\n",
    "\n",
    "                \n",
    "                                \n",
    "    ############            \n",
    "    # Evaluation on 100 pre-saved data\n",
    "    ############\n",
    "    running_loss = 0.0\n",
    "    running_total = 0\n",
    "    running_conf_mat = 0\n",
    "    running_accuracy = 0\n",
    "    for iteration in range(100):\n",
    "        \n",
    "        # generate one data\n",
    "        if flag_task == 'matching':\n",
    "            train_x = g.variable_size_graph(task_parameters)\n",
    "        if flag_task == 'clustering':\n",
    "            train_x = task_parameters['all_trainx'][iteration][1]\n",
    "        train_y = train_x.target\n",
    "        train_y = Variable( torch.LongTensor(train_y).type(dtypeLong) , requires_grad=False) \n",
    "        \n",
    "        # forward, loss\n",
    "        y = net.forward(train_x)\n",
    "        # compute loss weigth\n",
    "        labels = train_y.data.cpu().numpy()\n",
    "        V = labels.shape[0]\n",
    "        nb_classes = len(np.unique(labels)) \n",
    "        cluster_sizes = np.zeros(nb_classes)\n",
    "        for r in range(nb_classes):\n",
    "            cluster = np.where(labels==r)[0]\n",
    "            cluster_sizes[r] = len(cluster)    \n",
    "        weight = torch.zeros(nb_classes)\n",
    "        for r in range(nb_classes):\n",
    "            sumj = 0\n",
    "            for j in range(nb_classes):\n",
    "                if j!=r:\n",
    "                    sumj += cluster_sizes[j]\n",
    "            weight[r] = sumj/ V \n",
    "        loss = net.loss(y,train_y,weight)\n",
    "        loss_train = loss.data #[0]\n",
    "        running_loss += loss_train\n",
    "        running_total += 1\n",
    "        \n",
    "        # confusion matrix\n",
    "        S = train_y.data.cpu().numpy()\n",
    "        C = np.argmax( torch.nn.Softmax(dim=0)(y).data.cpu().numpy() , axis=1)\n",
    "        CM = confusion_matrix(S,C).astype(np.float32)\n",
    "        nb_classes = CM.shape[0]\n",
    "        train_y = train_y.data.cpu().numpy()\n",
    "        for r in range(nb_classes):\n",
    "            cluster = np.where(train_y==r)[0]\n",
    "            CM[r,:] /= cluster.shape[0]\n",
    "        running_conf_mat += CM\n",
    "        running_accuracy += np.sum(np.diag(CM))/ nb_classes\n",
    "\n",
    "        # confusion matrix\n",
    "        average_conf_mat = running_conf_mat/ running_total\n",
    "        average_accuracy = running_accuracy/ running_total\n",
    "        average_loss = running_loss/ running_total\n",
    "        \n",
    "    # print results\n",
    "    print('\\nloss(100 pre-saved data)= %.3f, accuracy(100 pre-saved data)= %.3f' % (average_loss,100* average_accuracy))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    #############\n",
    "    # output\n",
    "    #############\n",
    "    result = {}\n",
    "    result['final_loss'] = average_loss\n",
    "    result['final_acc'] = 100* average_accuracy\n",
    "    result['final_CM'] = 100* average_conf_mat\n",
    "    result['final_batch_time'] = t_stop\n",
    "    result['nb_param_nn'] = nb_param\n",
    "    result['plot_all_epochs'] = tab_results\n",
    "    #print(result)\n",
    "    \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "#run it\n",
    "result = our_graph_convnets(task_parameters,net_parameters,opt_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_loss': tensor(0.0077), 'final_acc': 99.69623523950577, 'final_CM': array([[ 99.39246  ,   0.6075297],\n",
      "       [  0.       , 100.       ]], dtype=float32), 'final_batch_time': 3.492062568664551, 'nb_param_nn': 114752, 'plot_all_epochs': [[0, tensor(0.8983), 37.90322542190552, 0.09132504463195801], [100, tensor(0.3736), 84.14436960220337, 2.6293108463287354], [200, tensor(0.1294), 93.98695540428162, 5.1134116649627686], [300, tensor(0.2085), 89.87065245211124, 7.5698935985565186], [400, tensor(0.1159), 92.87144559621811, 9.942087173461914], [500, tensor(0.0994), 95.64922562241554, 12.343241214752197], [600, tensor(0.1067), 94.87220051884651, 14.785802602767944], [700, tensor(0.0979), 95.75474333763123, 17.21157932281494], [800, tensor(0.0817), 96.51757776737213, 19.664326906204224], [900, tensor(0.0893), 96.68711705505848, 22.0413019657135], [1000, tensor(0.1065), 96.92660011351109, 24.426107168197632], [1100, tensor(0.0626), 97.4568675160408, 26.869237422943115], [1200, tensor(0.0235), 98.76869755983353, 29.290383338928223], [1300, tensor(0.0553), 98.22882008552551, 31.772753953933716], [1400, tensor(0.0217), 99.04038596153259, 34.20166325569153], [1500, tensor(0.0312), 98.53048133850098, 36.645589113235474], [1600, tensor(0.0372), 98.42752569913864, 39.0226833820343], [1700, tensor(0.0143), 99.2934759259224, 41.4761803150177], [1800, tensor(0.0754), 98.11887447535992, 43.91275238990784], [1900, tensor(0.0912), 97.2774399369955, 46.401299238204956], [2000, tensor(0.0149), 99.38953685760498, 48.85436129570007], [2100, tensor(0.0121), 99.49586135149002, 51.40894532203674], [2200, tensor(0.0511), 98.8292661011219, 54.0098295211792], [2300, tensor(0.0262), 99.18000531196594, 56.708781003952026], [2400, tensor(0.0261), 98.88899165391922, 59.79764676094055], [2500, tensor(0.0120), 99.44900995492935, 62.70263695716858], [2600, tensor(0.0418), 98.56664174795151, 65.51153993606567], [2700, tensor(0.0486), 98.51406049728394, 68.38123059272766], [2800, tensor(0.0114), 99.55834811925888, 71.3710765838623], [2900, tensor(0.0119), 99.506032705307, 74.27514147758484], [3000, tensor(0.0143), 99.22949260473251, 77.2614734172821], [3100, tensor(0.0128), 99.3841050863266, 80.3477189540863], [3200, tensor(0.0284), 98.83943647146225, 83.21993494033813], [3300, tensor(0.0171), 99.25479006767273, 86.26021099090576], [3400, tensor(0.0133), 99.44103926420212, 89.25437688827515], [3500, tensor(0.0100), 99.47796279191971, 92.2744836807251], [3600, tensor(0.0158), 99.31018221378326, 95.94481563568115], [3700, tensor(0.0087), 99.66870331764221, 99.49892854690552], [3800, tensor(0.0172), 99.24570524692535, 103.01501989364624], [3900, tensor(0.0087), 99.60110777616501, 106.54356527328491], [4000, tensor(0.0153), 99.3533445596695, 109.68892621994019], [4100, tensor(0.0117), 99.59339880943298, 112.98214983940125], [4200, tensor(0.0084), 99.66322910785675, 116.27808117866516], [4300, tensor(0.0085), 99.60957086086273, 119.67320513725281], [4400, tensor(0.0091), 99.6170169711113, 123.50732207298279], [4500, tensor(0.0077), 99.69756656885147, 126.99912405014038], [4600, tensor(0.0104), 99.56624150276184, 130.39835405349731], [4700, tensor(0.1002), 97.24427746236324, 134.17289447784424], [4800, tensor(0.0838), 97.79645358026028, 137.92065405845642], [4900, tensor(0.0119), 99.56082701683044, 141.41271662712097]]}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
